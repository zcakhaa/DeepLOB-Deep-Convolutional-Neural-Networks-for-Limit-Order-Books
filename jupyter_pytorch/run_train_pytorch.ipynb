{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660f01db",
   "metadata": {},
   "source": [
    "# DeepLOB: Deep Convolutional Neural Networks for Limit Order Books\n",
    "\n",
    "### Authors: Zihao Zhang, Stefan Zohren and Stephen Roberts\n",
    "Oxford-Man Institute of Quantitative Finance, Department of Engineering Science, University of Oxford\n",
    "\n",
    "This jupyter notebook is used to demonstrate our recent paper [2] published in IEEE Transactions on Singal Processing. We use FI-2010 [1] dataset and present how model architecture is constructed here. The FI-2010 is publicly avilable and interested readers can check out their paper [1]. The dataset can be downloaded from: https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649 \n",
    "\n",
    "Otherwise, it can be obtained from: https://drive.google.com/drive/folders/1Xen3aRid9ZZhFqJRgEMyETNazk02cNmv?usp=sharing\n",
    "\n",
    "\n",
    "[1] Ntakaris A, Magris M, Kanniainen J, Gabbouj M, Iosifidis A. Benchmark dataset for mid‐price forecasting of limit order book data with machine learning methods. Journal of Forecasting. 2018 Dec;37(8):852-66. https://arxiv.org/abs/1705.03233\n",
    "\n",
    "[2] Zhang Z, Zohren S, Roberts S. DeepLOB: Deep convolutional neural networks for limit order books. IEEE Transactions on Signal Processing. 2019 Mar 25;67(11):3001-12. https://arxiv.org/abs/1808.03668\n",
    "\n",
    "### This notebook runs on Pytorch 1.9.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f9725fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
    "# N, D = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fc7cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e54d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x(data):\n",
    "    df1 = data[:40, :].T\n",
    "    return np.array(df1)\n",
    "\n",
    "def get_label(data):\n",
    "    lob = data[-5:, :].T\n",
    "    return lob\n",
    "\n",
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    df = np.array(X)\n",
    "\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX, dataY\n",
    "\n",
    "def torch_data(x, y):\n",
    "    x = torch.from_numpy(x)\n",
    "    x = torch.unsqueeze(x, 1)\n",
    "    y = torch.from_numpy(y)\n",
    "    y = F.one_hot(y, num_classes=3)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34bfd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, data, k, num_classes, T):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "            \n",
    "        x = prepare_x(data)\n",
    "        y = get_label(data)\n",
    "        x, y = data_classification(x, y, self.T)\n",
    "        y = y[:,self.k] - 1\n",
    "        self.length = len(x)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23d99a",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We used no auction dataset that is normalised by decimal precision approach in their work. The first seven days are training data and the last three days are testing data. A validation set (20%) from the training set is used to monitor the overfitting behaviours.  \n",
    "\n",
    "The first 40 columns of the FI-2010 dataset are 10 levels ask and bid information for a limit order book and we only use these 40 features in our network. The last 5 columns of the FI-2010 dataset are the labels with different prediction horizons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071528bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 203800) (149, 50950) (149, 139587)\n"
     ]
    }
   ],
   "source": [
    "data_path = '/nfs/home/zihaoz/limit_order_book/data'\n",
    "\n",
    "# please change the data_path to your local path\n",
    "data_path = '/nfs/home/zihaoz/limit_order_book/data'\n",
    "\n",
    "dec_data = np.loadtxt(data_path + '/3.NoAuction_DecPre/NoAuction_DecPre_Training/Train_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n",
    "dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n",
    "\n",
    "dec_test1 = np.loadtxt(data_path + '/3.NoAuction_DecPre/NoAuction_DecPre_Testing/Test_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "dec_test2 = np.loadtxt(data_path + '/3.NoAuction_DecPre/NoAuction_DecPre_Testing/Test_Dst_NoAuction_DecPre_CF_8.txt')\n",
    "dec_test3 = np.loadtxt(data_path + '/3.NoAuction_DecPre/NoAuction_DecPre_Testing/Test_Dst_NoAuction_DecPre_CF_9.txt')\n",
    "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "\n",
    "print(dec_train.shape, dec_val.shape, dec_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff69dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([203701, 1, 100, 40]) torch.Size([203701])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataset_train = Dataset(data=dec_train, k=4, num_classes=3, T=100)\n",
    "dataset_val = Dataset(data=dec_val, k=4, num_classes=3, T=100)\n",
    "dataset_test = Dataset(data=dec_test, k=4, num_classes=3, T=100)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(dataset_train.x.shape, dataset_train.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68b0211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1288, 0.0080, 0.1286,  ..., 0.0060, 0.1276, 0.0223],\n",
      "          [0.1288, 0.0080, 0.1286,  ..., 0.0060, 0.1276, 0.0223],\n",
      "          [0.1287, 0.0135, 0.1286,  ..., 0.0060, 0.1276, 0.0223],\n",
      "          ...,\n",
      "          [0.1275, 0.0138, 0.1272,  ..., 0.0500, 0.1261, 0.0389],\n",
      "          [0.1273, 0.0030, 0.1272,  ..., 0.0200, 0.1261, 0.0389],\n",
      "          [0.1273, 0.0147, 0.1272,  ..., 0.0200, 0.1261, 0.0389]]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "torch.Size([1, 1, 100, 40]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=1, shuffle=True)\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d6af9e",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "Please find the detailed discussion of our model architecture in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc99dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplob(nn.Module):\n",
    "    def __init__(self, y_len):\n",
    "        super().__init__()\n",
    "        self.y_len = y_len\n",
    "        \n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, self.y_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e44da24a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deeplob(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 10), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(192, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deeplob(y_len = dataset_train.num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c96c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/zihaoz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "deeplob                                  --                        --\n",
       "├─Sequential: 1-1                        [1, 32, 94, 20]           --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 100, 20]          96\n",
       "│    └─LeakyReLU: 2-2                    [1, 32, 100, 20]          --\n",
       "│    └─BatchNorm2d: 2-3                  [1, 32, 100, 20]          64\n",
       "│    └─Conv2d: 2-4                       [1, 32, 97, 20]           4,128\n",
       "│    └─LeakyReLU: 2-5                    [1, 32, 97, 20]           --\n",
       "│    └─BatchNorm2d: 2-6                  [1, 32, 97, 20]           64\n",
       "│    └─Conv2d: 2-7                       [1, 32, 94, 20]           4,128\n",
       "│    └─LeakyReLU: 2-8                    [1, 32, 94, 20]           --\n",
       "│    └─BatchNorm2d: 2-9                  [1, 32, 94, 20]           64\n",
       "├─Sequential: 1-2                        [1, 32, 88, 10]           --\n",
       "│    └─Conv2d: 2-10                      [1, 32, 94, 10]           2,080\n",
       "│    └─Tanh: 2-11                        [1, 32, 94, 10]           --\n",
       "│    └─BatchNorm2d: 2-12                 [1, 32, 94, 10]           64\n",
       "│    └─Conv2d: 2-13                      [1, 32, 91, 10]           4,128\n",
       "│    └─Tanh: 2-14                        [1, 32, 91, 10]           --\n",
       "│    └─BatchNorm2d: 2-15                 [1, 32, 91, 10]           64\n",
       "│    └─Conv2d: 2-16                      [1, 32, 88, 10]           4,128\n",
       "│    └─Tanh: 2-17                        [1, 32, 88, 10]           --\n",
       "│    └─BatchNorm2d: 2-18                 [1, 32, 88, 10]           64\n",
       "├─Sequential: 1-3                        [1, 32, 82, 1]            --\n",
       "│    └─Conv2d: 2-19                      [1, 32, 88, 1]            10,272\n",
       "│    └─LeakyReLU: 2-20                   [1, 32, 88, 1]            --\n",
       "│    └─BatchNorm2d: 2-21                 [1, 32, 88, 1]            64\n",
       "│    └─Conv2d: 2-22                      [1, 32, 85, 1]            4,128\n",
       "│    └─LeakyReLU: 2-23                   [1, 32, 85, 1]            --\n",
       "│    └─BatchNorm2d: 2-24                 [1, 32, 85, 1]            64\n",
       "│    └─Conv2d: 2-25                      [1, 32, 82, 1]            4,128\n",
       "│    └─LeakyReLU: 2-26                   [1, 32, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-27                 [1, 32, 82, 1]            64\n",
       "├─Sequential: 1-4                        [1, 64, 82, 1]            --\n",
       "│    └─Conv2d: 2-28                      [1, 64, 82, 1]            2,112\n",
       "│    └─LeakyReLU: 2-29                   [1, 64, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-30                 [1, 64, 82, 1]            128\n",
       "│    └─Conv2d: 2-31                      [1, 64, 82, 1]            12,352\n",
       "│    └─LeakyReLU: 2-32                   [1, 64, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-33                 [1, 64, 82, 1]            128\n",
       "├─Sequential: 1-5                        [1, 64, 82, 1]            --\n",
       "│    └─Conv2d: 2-34                      [1, 64, 82, 1]            2,112\n",
       "│    └─LeakyReLU: 2-35                   [1, 64, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-36                 [1, 64, 82, 1]            128\n",
       "│    └─Conv2d: 2-37                      [1, 64, 82, 1]            20,544\n",
       "│    └─LeakyReLU: 2-38                   [1, 64, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-39                 [1, 64, 82, 1]            128\n",
       "├─Sequential: 1-6                        [1, 64, 82, 1]            --\n",
       "│    └─MaxPool2d: 2-40                   [1, 32, 82, 1]            --\n",
       "│    └─Conv2d: 2-41                      [1, 64, 82, 1]            2,112\n",
       "│    └─LeakyReLU: 2-42                   [1, 64, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-43                 [1, 64, 82, 1]            128\n",
       "├─LSTM: 1-7                              [1, 82, 64]               66,048\n",
       "├─Linear: 1-8                            [1, 3]                    195\n",
       "==========================================================================================\n",
       "Total params: 143,907\n",
       "Trainable params: 143,907\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 35.53\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 4.97\n",
       "Params size (MB): 0.58\n",
       "Estimated Total Size (MB): 5.56\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1, 1, 100, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "033ba969",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ac4a5",
   "metadata": {},
   "source": [
    "# Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a582c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to encapsulate the training loop\n",
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
    "    \n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    best_test_loss = np.inf\n",
    "    best_test_epoch = 0\n",
    "\n",
    "    for it in tqdm(range(epochs)):\n",
    "        \n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            # move data to GPU\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "            # print(\"inputs.shape:\", inputs.shape)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            # print(\"about to get model output\")\n",
    "            outputs = model(inputs)\n",
    "            # print(\"done getting model output\")\n",
    "            # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # Backward and optimize\n",
    "            # print(\"about to optimize\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss) # a little misleading\n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            torch.save(model, './best_val_model_pytorch')\n",
    "            best_test_loss = test_loss\n",
    "            best_test_epoch = it\n",
    "            print('model saved')\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d996299a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:44<36:10, 44.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 1/50, Train Loss: 0.9298,           Validation Loss: 0.9991, Duration: 0:00:44.297625, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [01:28<35:34, 44.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Train Loss: 0.8267,           Validation Loss: 1.0260, Duration: 0:00:44.576334, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [02:14<35:19, 45.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 3/50, Train Loss: 0.7981,           Validation Loss: 0.9216, Duration: 0:00:45.849619, Best Val Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [03:00<34:52, 45.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 4/50, Train Loss: 0.7783,           Validation Loss: 0.9136, Duration: 0:00:46.074160, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [03:46<34:16, 45.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 5/50, Train Loss: 0.7645,           Validation Loss: 0.9067, Duration: 0:00:46.075129, Best Val Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [04:32<33:23, 45.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 6/50, Train Loss: 0.7542,           Validation Loss: 0.8915, Duration: 0:00:45.207159, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/50 [05:17<32:35, 45.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 7/50, Train Loss: 0.7460,           Validation Loss: 0.8800, Duration: 0:00:45.339670, Best Val Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [06:03<32:00, 45.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 0.7381,           Validation Loss: 0.8881, Duration: 0:00:46.289839, Best Val Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [06:49<31:20, 45.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 0.7311,           Validation Loss: 0.8912, Duration: 0:00:46.154672, Best Val Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [07:36<30:41, 46.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 10/50, Train Loss: 0.7268,           Validation Loss: 0.8752, Duration: 0:00:46.433728, Best Val Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [08:22<29:59, 46.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Train Loss: 0.7216,           Validation Loss: 0.8758, Duration: 0:00:46.398751, Best Val Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [09:09<29:20, 46.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 0.7164,           Validation Loss: 0.8819, Duration: 0:00:46.756192, Best Val Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 13/50 [09:54<28:24, 46.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 0.7112,           Validation Loss: 0.8752, Duration: 0:00:45.490455, Best Val Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [10:46<28:33, 47.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 0.7080,           Validation Loss: 0.9027, Duration: 0:00:51.108728, Best Val Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [11:32<27:34, 47.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 0.7042,           Validation Loss: 0.8811, Duration: 0:00:46.528743, Best Val Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [12:18<26:37, 46.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 16/50, Train Loss: 0.7005,           Validation Loss: 0.8699, Duration: 0:00:46.322790, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [13:05<25:46, 46.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Train Loss: 0.6978,           Validation Loss: 0.8743, Duration: 0:00:46.529472, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 18/50 [13:51<24:51, 46.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Train Loss: 0.6944,           Validation Loss: 0.8763, Duration: 0:00:46.059254, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [14:37<23:56, 46.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Train Loss: 0.6917,           Validation Loss: 0.8920, Duration: 0:00:45.657430, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [15:22<22:56, 45.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Train Loss: 0.6891,           Validation Loss: 0.8843, Duration: 0:00:44.895878, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 21/50 [16:08<22:18, 46.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Train Loss: 0.6868,           Validation Loss: 0.8869, Duration: 0:00:46.719954, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 22/50 [16:55<21:34, 46.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Train Loss: 0.6841,           Validation Loss: 0.8817, Duration: 0:00:46.488570, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [17:42<20:56, 46.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Train Loss: 0.6823,           Validation Loss: 0.8968, Duration: 0:00:47.151411, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 24/50 [18:27<20:01, 46.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Train Loss: 0.6802,           Validation Loss: 0.8787, Duration: 0:00:45.487472, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 25/50 [19:13<19:14, 46.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Train Loss: 0.6777,           Validation Loss: 0.8749, Duration: 0:00:46.066923, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 26/50 [20:00<18:31, 46.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Train Loss: 0.6764,           Validation Loss: 0.9090, Duration: 0:00:46.634666, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 27/50 [20:47<17:50, 46.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Train Loss: 0.6747,           Validation Loss: 0.8937, Duration: 0:00:47.073876, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 28/50 [21:34<17:07, 46.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Train Loss: 0.6725,           Validation Loss: 0.8820, Duration: 0:00:47.055143, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [22:20<16:14, 46.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Train Loss: 0.6713,           Validation Loss: 0.8831, Duration: 0:00:45.695207, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [23:07<15:29, 46.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Train Loss: 0.6694,           Validation Loss: 0.8776, Duration: 0:00:46.592302, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 31/50 [23:54<14:45, 46.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Train Loss: 0.6673,           Validation Loss: 0.8842, Duration: 0:00:46.967561, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 32/50 [24:39<13:54, 46.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Train Loss: 0.6666,           Validation Loss: 0.8878, Duration: 0:00:45.843882, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 33/50 [25:25<13:03, 46.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Train Loss: 0.6647,           Validation Loss: 0.8925, Duration: 0:00:45.462790, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 34/50 [26:11<12:16, 46.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Train Loss: 0.6637,           Validation Loss: 0.8836, Duration: 0:00:45.852703, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 35/50 [26:56<11:25, 45.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Train Loss: 0.6626,           Validation Loss: 0.8799, Duration: 0:00:44.929479, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 36/50 [27:41<10:36, 45.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Train Loss: 0.6617,           Validation Loss: 0.8800, Duration: 0:00:44.979946, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 37/50 [28:26<09:51, 45.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Train Loss: 0.6609,           Validation Loss: 0.8762, Duration: 0:00:45.477532, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 38/50 [29:12<09:08, 45.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Train Loss: 0.6598,           Validation Loss: 0.8915, Duration: 0:00:46.257106, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [29:59<08:26, 46.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Train Loss: 0.6592,           Validation Loss: 0.8825, Duration: 0:00:46.805625, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 40/50 [30:45<07:41, 46.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Train Loss: 0.6583,           Validation Loss: 0.8900, Duration: 0:00:46.275751, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [31:31<06:54, 46.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Train Loss: 0.6564,           Validation Loss: 0.8927, Duration: 0:00:46.078077, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 42/50 [32:18<06:09, 46.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Train Loss: 0.6560,           Validation Loss: 0.8959, Duration: 0:00:46.497753, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 43/50 [33:04<05:23, 46.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Train Loss: 0.6552,           Validation Loss: 0.8928, Duration: 0:00:46.139226, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [33:50<04:37, 46.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 0.6547,           Validation Loss: 0.8842, Duration: 0:00:46.337848, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [34:37<03:52, 46.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Train Loss: 0.6538,           Validation Loss: 0.8822, Duration: 0:00:46.859851, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [35:23<03:05, 46.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Train Loss: 0.6531,           Validation Loss: 0.8859, Duration: 0:00:45.958237, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [36:09<02:18, 46.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Train Loss: 0.6524,           Validation Loss: 0.8887, Duration: 0:00:45.888164, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [36:56<01:32, 46.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Train Loss: 0.6516,           Validation Loss: 0.8906, Duration: 0:00:47.092747, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 49/50 [37:43<00:46, 46.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Train Loss: 0.6507,           Validation Loss: 0.8891, Duration: 0:00:46.648716, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [38:30<00:00, 46.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Train Loss: 0.6500,           Validation Loss: 0.8941, Duration: 0:00:46.618582, Best Val Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
    "                                    train_loader, val_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ea8fd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb010886ed0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAFlCAYAAACqbgrWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABZnklEQVR4nO3dd3ib1f3+8fex5L1jO3GcPckeYEIgQBIoEKDsljICFNpS2gKdfKETShf9dVFaOkKBUlpWaaFhlABlhZ0dsshedpx47ymd3x9HnnESJ5Ytyb5f16VL0vM8ko4T2XpunXM+x1hrERERERERkfAXFeoGiIiIiIiISNcowImIiIiIiEQIBTgREREREZEIoQAnIiIiIiISIRTgREREREREIoQCnIiIiIiISITwhroBHWVmZtqRI0eGuhkiIiIiIiIhsWLFiiJrbVZn+8IuwI0cOZLly5eHuhkiIiIiIiIhYYzZdah9GkIpIiIiIiISIRTgREREREREIoQCnIiIiIiISIQIuzlwIiIiIiISGRobG9m7dy91dXWhbkpEiouLY+jQoURHR3f5MQpwIiIiIiJyTPbu3UtycjIjR47EGBPq5kQUay3FxcXs3buXUaNGdflxGkIpIiIiIiLHpK6ujoyMDIW3Y2CMISMj46h7LxXgRERERETkmCm8Hbtj+bdTgBMRERERkYhUVlbGH/7wh2N67HnnnUdZWVmXj7/rrrv45S9/eUyvFUwKcCIiIiIiEpEOF+CampoO+9gXX3yRtLS0HmhVz1KAExERERGRiHTHHXewbds2ZsyYwW233cYbb7zBaaedxoUXXsikSZMAuPjiiznhhBOYPHkyixYtannsyJEjKSoqYufOnUycOJEvfOELTJ48mbPPPpva2trDvu7q1auZPXs206ZN45JLLqG0tBSA++67j0mTJjFt2jSuuOIKAN58801mzJjBjBkzmDlzJpWVld36mVWFUkREREREuu2Hz61nQ35FUJ9zUk4Kd14w+ZD777nnHtatW8fq1asBeOONN1i5ciXr1q1rqez40EMPMWDAAGpraznxxBO57LLLyMjIaPc8W7Zs4fHHH+eBBx7g8ssv51//+hcLFy485Otee+21/O53v2Pu3Ln84Ac/4Ic//CH33nsv99xzDzt27CA2NrZleOYvf/lL7r//fubMmUNVVRVxcXHd+jdRD1xvqDoAFftC3QoRERERkT5v1qxZ7cry33fffUyfPp3Zs2ezZ88etmzZctBjRo0axYwZMwA44YQT2Llz5yGfv7y8nLKyMubOnQvAddddx1tvvQXAtGnTuPrqq/n73/+O1+v6yubMmcM3vvEN7rvvPsrKylq2Hyv1wPW02jJ44ExIGQyfeznUrRERERER6RGH6ynrTYmJiS2333jjDV599VXee+89EhISmDdvXqdl+2NjY1tuezyeIw6hPJQXXniBt956i+eee46f/OQnfPTRR9xxxx2cf/75vPjii8yZM4clS5YwYcKEY3p+UA9cz7IWnrsVyndD/mrwHX4ipYiIiIiIdF1ycvJh55SVl5eTnp5OQkICmzZt4v333+/2a6amppKens7SpUsBePTRR5k7dy5+v589e/Ywf/58fv7zn1NeXk5VVRXbtm1j6tSp3H777Zx44ols2rSpW6+vHrietOKvsOE/MPRE2LsMijbDoEmhbpWIiIiISJ+QkZHBnDlzmDJlCueeey7nn39+u/0LFizgT3/6ExMnTuS4445j9uzZQXndRx55hJtuuomamhpGjx7Nww8/jM/nY+HChZSXl2Ot5dZbbyUtLY3vf//7vP7660RFRTF58mTOPffcbr22sdYG5YcIltzcXLt8+fJQN6P7DmyERfNg+Mlwzk/gj6fAJYtg+mdC3TIRERERkaDYuHEjEydODHUzIlpn/4bGmBXW2tzOjtcQyp7QUAP/vB5ik+GSP0PmceCNg4K1oW6ZiIiIiIhEMA2h7AlLvgOFG2HhvyF5kNs2cBIUfBTadomIiIiISERTD1ywrX8GVjwMc74KY89s3Z491fXAhdmQVRERERERiRwKcMFUugsWfxWGnABnfL/9vuypUFsKFXmhaZuIiIiIiEQ8Bbhg8TXCvz4HWLjsQfBEt98/eLq71jBKERERERE5RgpwwfL6T91SARfcCwNGHbx/4CTAwD4VMhERERERkWOjABcM216Ht38DM6+BKZd1fkxsEmSMUSVKEREREZEgKSsr4w9/+MMxP/7ee++lpqam033z5s0jHJc3U4DrrqpCeOaLkDkezv354Y/NnqohlCIiIiIiQdKTAS5cKcB1h98Pz94EtWXw6YchJvHwx2dPg7Jd7ngREREREemWO+64g23btjFjxgxuu+02AH7xi19w4oknMm3aNO68804AqqurOf/885k+fTpTpkzhySef5L777iM/P5/58+czf/78w77O448/ztSpU5kyZQq33347AD6fj89+9rNMmTKFqVOn8pvf/AaA++67j0mTJjFt2jSuuOKKoP/MWgeuO977PWx9Fc7/FQyafOTjs6e56/3rYOSpPds2EREREZHe9N87gj/aLHsqnHvPIXffc889rFu3jtWrVwPw8ssvs2XLFj788EOstVx44YW89dZbFBYWkpOTwwsvvABAeXk5qamp/PrXv+b1118nMzPzkK+Rn5/P7bffzooVK0hPT+fss8/m2WefZdiwYeTl5bFu3TrA9QY2t2nHjh3Exsa2bAsm9cAdq7wV8L8fwoRPQu7nuvaY7KnuWsMoRURERESC7uWXX+bll19m5syZHH/88WzatIktW7YwdepUXnnlFW6//XaWLl1Kampql59z2bJlzJs3j6ysLLxeL1dffTVvvfUWo0ePZvv27dxyyy289NJLpKSkADBt2jSuvvpq/v73v+P1Br+/TD1wx6KuAp6+AZIHw0W/B2O69rjkQZA0SAFORERERPqew/SU9RZrLd/+9rf54he/eNC+lStX8uKLL/K9732PM888kx/84Afdeq309HTWrFnDkiVL+NOf/sRTTz3FQw89xAsvvMBbb73Fc889x09+8hM++uijoAY59cAdLWvh+a9D2R647C8Qn350j8+eqqUERERERESCIDk5mcrKypb755xzDg899BBVVVUA5OXlceDAAfLz80lISGDhwoXcdtttrFy5stPHd2bWrFm8+eabFBUV4fP5ePzxx5k7dy5FRUX4/X4uu+wyfvzjH7Ny5Ur8fj979uxh/vz5/PznP6e8vLylLcGiHrijtfofsO5pOON7MHz20T8+eypsfxOaGsAbE/z2iYiIiIj0ExkZGcyZM4cpU6Zw7rnn8otf/IKNGzdy8sknA5CUlMTf//53tm7dym233UZUVBTR0dH88Y9/BODGG29kwYIF5OTk8Prrr3f6GoMHD+aee+5h/vz5WGs5//zzueiii1izZg3XX389fr8fgJ/97Gf4fD4WLlxIeXk51lpuvfVW0tLSgvozG2vt4Q8w5iHgk8ABa+2UTvYb4LfAeUAN8Flr7crAvuuA7wUO/bG19pEjNSg3N9eG43oLABR+DIvmwZAT4Nr/QJTn6J9j3b/c8MsvLoXB04LeRBERERGR3rJx40YmTpwY6mZEtM7+DY0xK6y1uZ0d35UhlH8FFhxm/7nAuMDlRuCPgRcdANwJnATMAu40xhzleMMw0ljngld0PFz6wLGFN4Ds6e5aC3qLiIiIiMhROmKAs9a+BZQc5pCLgL9Z530gzRgzGDgHeMVaW2KtLQVe4fBBMLy9/D1X/v/iP0LK4GN/ngGjIDpRhUxEREREROSoBaOIyRBgT5v7ewPbDrX9IMaYG40xy40xywsLC4PQpCDb8gosewBmfwXGn9O954ryuDXjFOBEREREROQohUUVSmvtImttrrU2NysrK9TNOdiIU2D+d+ETdwbn+QZPcwHuCPMPRURERETC3ZFqasihHcu/XTACXB4wrM39oYFth9oeeWISYe7/gTc2OM+XPRXqK6B0Z3CeT0REREQkBOLi4iguLlaIOwbWWoqLi4mLizuqxwVjGYHFwM3GmCdwBUvKrbX7jDFLgJ+2KVxyNvDtILxe5Mue6q4LPnJz4kREREREItDQoUPZu3cvYTkNKgLExcUxdOjQo3rMEQOcMeZxYB6QaYzZi6ssGQ1grf0T8CJuCYGtuGUErg/sKzHG/AhYFniqu621hyuG0n8MnATG4wLcpAtD3RoRERERkWMSHR3NqFHqkOhNRwxw1torj7DfAl85xL6HgIeOrWl9WHQ8ZI7XUgIiIiIiInJUwqKISb+UPVWVKEVERERE5KgowIVK9lSoyIPq4lC3REREREREIoQCXKgMnuau96sXTkREREREukYBLlQGBSpR7tM8OBERERER6RoFuFBJzICUIZoHJyIiIiIiXaYAF0oqZCIiIiIiIkdBAS6UsqdB0WZorA11S0REREREJAIowIVS9lSwPjiwIdQtERERERGRCKAAF0rZgUImGkYpIiIiIiJdoAAXSukjITZFlShFRERERKRLFOBCyRgVMhERERERkS5TgAu17Kmwfz34faFuiYiIiIiIhDkFuFDLngaN1VCyI9QtERERERGRMKcAF2othUzWhLYdIiIiIiIS9hTgQi1rAkRFax6ciIiIiIgckQJcqHljXIhTgBMRERERkSNQgAsHg6dpKQERERERETkiBbhwkD0Vqg9A5f5Qt0RERERERMKYAlw4aClkomGUIiIiIiJyaApw4aAlwGkYpYiIiIiIHJoCXDiIS4W0EQpwIiIiIiJyWApw4SJ7qoZQioiIiIjIYSnAhYvsaVC8DeqrQt0SEREREREJUwpw4WLwNMDC/vWhbomIiIiIiIQpBbhwoUImIiIiIiJyBApw4SJlCMSnax6ciIiIiIgckgJcuDDGzYNTD5yIiIiIiByCAlw4yZ4K+zeArynULRERERERkTCkABdOsqeBrx6Kt4S6JSIiIiIiEoYU4MJJSyETzYMTEREREZGDdSnAGWMWGGM+NsZsNcbc0cn+EcaY/xlj1hpj3jDGDG2zz2eMWR24LA5m4/uczPHgiYV9a0LdEhERERERCUPeIx1gjPEA9wNnAXuBZcaYxdbaDW0O+yXwN2vtI8aYM4CfAdcE9tVaa2cEt9l9lMcLgyapB05ERERERDrVlR64WcBWa+12a20D8ARwUYdjJgGvBW6/3sl+6arsqS7AWRvqloiIiIiISJjpSoAbAuxpc39vYFtba4BLA7cvAZKNMRmB+3HGmOXGmPeNMRd39gLGmBsDxywvLCzseuv7ouxpUFsCFXmhbomIiIiIiISZYBUx+RYw1xizCpgL5AG+wL4R1tpc4CrgXmPMmI4PttYustbmWmtzs7KygtSkCJU9zV1rGKWIiIiIiHTQlQCXBwxrc39oYFsLa22+tfZSa+1M4LuBbWWB67zA9XbgDWBmt1vdlw2aBBgFOBEREREROUhXAtwyYJwxZpQxJga4AmhXTdIYk2mMaX6ubwMPBbanG2Nim48B5gBti59IR7HJMGC0KlGKiIiIiMhBjhjgrLVNwM3AEmAj8JS1dr0x5m5jzIWBw+YBHxtjNgODgJ8Etk8Elhtj1uCKm9zToXqldGbwNPXAiYiIiIjIQY64jACAtfZF4MUO237Q5vbTwNOdPO5dYGo329j/ZE+F9c9AbRnEp4W6NSIiIiIiEiaCVcREgqm5kMn+9aFth4iIiIiIhBUFuHDUUolybWjbISIiIiIiYUUBLhwlD4LEgZoHJyIiIiIi7SjAhavsqeqBExERERGRdhTgwtXgaXBgEzQ1hLolIiIiIiISJhTgwlX2VPA3QuGmULdERERERETChAJcuGopZKJ5cCIiIiIi4ijAhasBoyE6QQFORERERERaKMCFqygPDJqiQiYiIiIiItJCAa4L8stqefDtHZRU93JBkeyprgfO2t59XRERERERCUsKcF2wp6SGHz2/gTV7ynr3hbOnQn0FlO3q3dcVEREREZGwpADXBZNyUgBYn1/euy88OFDIZJ+GUYqIiIiIiAJclyTHRTMiI4H1+RW9+8IDJ4GJUiETEREREREBFOC6bHJOSu8HuOh4yByvACciIiIiIoACXJdNzklld0kNFXWNvfvC2VNViVJERERERAAFuC5rnge3obd74bKnQUUeVBf37uuKiIiIiEjYUYDroskhC3BT3fVzt8Kud7WkgIiIiIhIP6YA10UDk+PISo7t/Xlwo06HU26BHUvh4XPh/pPg/T9CbWnvtkNEREREREJOAe4ouEImvbyUQJQHzv4xfHMTXHQ/xCbBS3fArybAM1+CPcvUKyciIiIi0k94Q92ASDJpcApvbymivslHrNfTuy8ekwAzF7rLvjWw/GH46J+w5jEYNAVyr4epl0NcSu+2S0REREREeo164I7C5JxUmvyWzQVVoW3I4Olwwb2uV+6T97q14l74puuVW3wr5K8KbftERERERKRHKMAdheZCJr0+jPJQYpNdz9sX34LPvwZTLoG1T8Giee6y4hFoqA51K0VEREREJEgU4I7C8AEJJMV6e7+QyZEYA0NPcHPkvrkJzv0FNNW7ypW/mgDPfQ12vQd+f6hbKiIiIiIi3aA5cEchKsowaXAICpkcjfg0OOlGmPUF2POBmyu35glY8TCkDoepl7m5coMmhbqlIiIiIiJylNQDd5Qm5aSwqaASnz/MKz8aA8Nnw6V/htu2wiWLIOs4eOc++OPJ8Mc58PZvoGxPqFsqIiIiIiJdpAB3lCbnpFDT4GNncQTNLYtNgumfgYVPwzc/dkMso+Ph1bvg3inw8Hmup66mJNQtFREJf1q6RUREQkgB7ihNzkkFCL95cF2VlOWGWH7+Vbh1Fcz/HlQXwvNfg1+Oh8evhHX/hoaaULdURCT8VBXCb6fBf26GxtpQt0ZERPohBbijNHZgEjGeqPCeB9dVA0bD3NvgKx/CjW/CSV90SxA8fT38chw8cxNs/Z+Kn4iINHv9x1CeB6sehQfPgpIdoW6RiIj0MwpwRynGG8W4QUlsiNQeuM4YAzkz4JyfwNfXw7WLYfLFsOlF+Pul8MRVUFsa6laKiITWvrVueZaTboKrnnJziBfNhY9fCnXLRESkH1GAOwaTc1JYn1+B7YvzIKI8MHquW5LgW5vhnJ/B1lfhz3Mhf3WoWyciEhrWwkt3QMIAmPt/MP4c+OKbkDYCHv8M/O9H4PeFupUiItIPdCnAGWMWGGM+NsZsNcbc0cn+EcaY/xlj1hpj3jDGDG2z7zpjzJbA5bpgNj5UJuekUlLdQEFFXaib0rOi4+DkL8P1/wV/Ezx4Nqz4qybwy6H5GkPdApGeseE/sOsdOOP7brkWgPSR8LlX4PhrYekv4dFLoLoolK0UEZF+4IgBzhjjAe4HzgUmAVcaYzouIvZL4G/W2mnA3cDPAo8dANwJnATMAu40xqQHr/mhMTknBYD1eX1oGOXhDDsRvvgWjDgFnvsqPPtlFTmRg33wZ7hnBGx7LdQtEQmuxlp4+fswaKoLa21Fx8GFv4MLfw+734c/nw57loWmnSIi0i90pQduFrDVWrvdWtsAPAFc1OGYSUDzWdvrbfafA7xirS2x1pYCrwALut/s0Jo4OAVjYMO+fhLgABIzYeG/YO7tsOZxN3m/eFuoWyXhYt8aWPJdaKqDJxZC3spQt0gkeN79PZTvhgU/c8PMO3P8NfD5VyDKCw+fCx8+oNEKIiLSI7oS4IYAbVd73hvY1tYa4NLA7UuAZGNMRhcfG3ESY72MykjsG5Uoj0aUB+Z/B65+GiryYNE82LA41K2SUGuogX99HhIy4KalkJgB//gUFG0NdctEuq8iH97+NUy6CEaddvhjB0938+LGnAEvfgv+/QVoiKA1Q0VEJCIEq4jJt4C5xphVwFwgD+jybG5jzI3GmOXGmOWFhYVBalLPmhQoZNIvjfuEG1KZMRaeusb1vGjuU/+15DtQtBku+RMMmgzXPAsYNx+oYl+oWyfSPa/e5YqTnPWjrh0fnw5XPuHmyq37FzxwJhRt6dEmiohI/9KVAJcHDGtzf2hgWwtrbb619lJr7Uzgu4FtZV15bODYRdbaXGttblZW1tH9BCEyOSeVvaW1lNf00+CSNhxueAlO/AK893t45AKdrPdHG5+HFQ/DKbfAmPluW8YYWPg01Ja4ZSi0BIV0pngb7Hov1K04vD0fwton3fs7fUTXHxcVBad/Cxb+G6oPwKL5rgiKiIhIEHQlwC0DxhljRhljYoArgHbj5owxmcaY5uf6NvBQ4PYS4GxjTHqgeMnZgW0Rb1JzIZN9/WwYZVveWDj/l3DpX9wcqD+fBjveCnWrpLdU7IPFt0D2NDjjB+335cyEK/4BxVvh8StdEQiRZmuehD+d2jpXLBz5/fDf2yF5MJz69WN7jjHz3WiFrOPgqWs1WkEkHPn9ULoLNr8M79wH//kKPHWdWxpkzZOQvwrqq0LdSpF2vEc6wFrbZIy5GRe8PMBD1tr1xpi7geXW2sXAPOBnxhgLvAV8JfDYEmPMj3AhEOBua21JD/wcva65EuWG/ApOGZMZ4taE2LRPQ/ZUN5zybxfBGd+DOV9330JL3+T3wzNfdMHssgfBG3PwMaPnwaWL4J/Xu8tn/g6eI/7Jkb6ssc6tpbbiYRgxB2JT3Fyx6iKYdwcYE+oWtlr7JOSvhEv+DLFJx/48qUPdUixLvuNGK+SthE8/DMnZwWuriByZ3welO6HwYyjc1HpdtBka21TWThzofuc3Pge2zWyglCGQOQ4yx7e/JGeH198uOTqV+2HX2zDpkog6bzXhthh1bm6uXb58eaib0SUn/fRVThmTyW8+MyPUTQkP9ZWw+FZY/28Yv8DNiYqP+FUjpDPv3AevfB8+eS/kXn/4Yz98wJ2kz1zoSq3rg65/Kt3leqH2rYY5X23ttX3uVlj9Dzcc+9z/Fx4foPWV8LtcF74+90rw2rT2KbcUS3QCnP0jmHZFePy8/YHfd+gKotK3NNa5oFb0cfuwVrQFfPWtx6UMcb3jWRNcEMua4O4nDHD7mxqgdIcLeM2PL9rsrhsqW58nJrlNsBvnnmPUXIhL6dUfW7qough2LoUdS9110Wa3/YtvuUJUYcQYs8Jam9vZPn0d3g2Tc1L7XyXKw4lNhk89BMNPdt82/3kuXP6IG04nfUf+avjf3TDhk3DCZ498/KwvQHUhvPlzSMyCT9zVww2MINa6np7yvTDtM5A27MiPiUSbl8C/b3Q/7xWPwYTzW/dddL87YXr3d27e5MV/6rxHtzct/TVUFbhhwMEMWNMud6MVFt8Cz34JVvwVzvtF2J00RDxroWS7W3h913uw+133Ozb5UjjlZv17d1VdBTTVQ1IY1iaoLXPhqmQ7lOwI3N7pris6lFpIG+7C2Zj5gZA2wQWtuNTDv4Y3JhDwjoOJF7RutxYqC1xAbAl1m10YWPuEOyYm2S0tctIXIX1kEH9wOWo1Je5vQXNgO7DBbY9JcuerMxfCyNNg0JTQtvMoqQeuG3718sf84Y1trP/hOcRF65u9dvYsg39+Fir3wYmfh/nfDs/eOF9j4Ju6za3frBVthrLdMP0K10ugYX+tGqpdMG+ohi+90/pN5ZFYC89/3Q2dO+dncPKXe7adkaCxFp77WusHPgbGfsItFH3cueCJDmXrgsPXBG/8FJb+ygWXy/8GA0Z3fuzb98Krd8KYM+Ezj0JMYq82tUXJDrj/JJh8CVz65555Db8f1jwGr9zpQmvuDW7oeTj+jYwEfh/sX9ca1na954rHgFveZPjJbi3Tj56GhirXO3LKrTD2TI0IOJQ9y1yPeXUhTP20C76DJvfe6zeHpNId7neyZHvr7dIdBxfHShwIA0a5vy/po9zt5h6x3vxbUl8J+9a6z7r1z4D1w3Hnwclfce9Dvd/c/21tqfv/rSpwQxirCqCuHOLS3O9swoDAdeASl9r1HvS6cvc3YOdSV5eh4CPAgjcehp8Eo06HkadDzoyw/5w9XA+cAlw3vLRuHzf9fSX/+cocpg9LC3Vzwk9NCbz2Y/eHLC7NnaCc8NnQDGOpK2//TVnz7ZLt4G9qPS4p2/3Bj06ALUtg9HzXq9jVoNLXPfdVWPEIXPsfGD336B7r97lQv3ExXPqA643or8r2wJNXu+I/874D0z8Dq/4Bq/4Olfmup3LGVXD8da6qZySqOgBP3+A+RI+/Ds79OUTHH/4xKx91Qypzjoer/xma37snF8LW1+CW5ZCS07OvVVsKr/8Ulv3FhbdP3AUzFmpY5ZE01bu5hLvegd3vuWqh9YFlfVKHw4iT3cnyiFPcSXzzSXNtmev1/OBP7svFgZPg5Jth6qdcUS5xJ9cfPuBG0aQOcWsarnnCzREbcybMudUF4J4KIuV7Yc3jsPox9/nczERB6jAXzJoDWnNYSx/ZvXmqPaU8z/1ur3jY/a4Png6zv+K+HAr1KIOe4PdDTZELZh3DWWUBVO1vvfY1HPx442k/57D9Tvc3siXUDWgf8uLTXdG0HUvdMH3rB08sDJvletdGnQZDToi433MFuB6yp6SG0/7f6/z0kqlcddLwUDcnfBV85Kq57XoHBk11J3Ij5/Tc6/maYMvLsPXV1rBWVdC6P8oLA8Z0Mhl5bPshFSsegRe+6ebBXPk4DJzYc22OBBufcye3c74KZ919bM/RWOcW+d79Hlz5pFtTsL/ZsRT+eZ3r/b30AThuQes+v8+9b1f+DT7+r/swG3Gq65WbdOGRA1C42PWeC+t1ZfDJ37gw2lUbn3fBb8AoV4Y/dUhPtfJgO95yS6Kc8X23DEBv2bcWXrwN9rwPQ3JddV8NPXesdYup718Hez5w7628Fa1zmbImtIa14Sd3bRhyU4Nbo++937vnTRrkhrrl3tC/e0Ebqt089nVPt5/HXlMCyx+EDxa5ns3sqa4Hc/IlwenBaKyDTc+7ubDbXges+7s38QK33uyAUS68RWroaahxIy3e/6M7J0ka5Ob85t4AiRmhbt3R8TVB+e7Woasl21svpTs7D2bx6e7L8eRBh7jOdv8mMYnuPVhT7C61Je6913y/4+3awP3m14yKhqG5rYFt6CyIjuvVf55gU4DrIdZapv/wZS6YnsNPLpka6uaEN2vdcIKXvw8Ve90f/rN+FNw5PxX73InvykfcGPjYVDd2vXkYRXNQSx/R9Q+d3R+40NJY46rRTfxk8NobSSry4Y+nQNoIV9ShOx+kdRXw1/Pdt2XXPef+4PYH1rpv/pd81/WqXfGYe18eSuV+d0Kz8m9uyFBcqpsnd/y17gTqWDTWueHBpTvch23JDvd/OWquO/mNSTi2521mrTspfuVO93t2+aOQfQzzCnYsdctPxKe5heEzx3avXV3ha4JFc11PzleW9f4Hv7Wup+OVH7hhayd8Fs78Qf/q/W9qcPOKCj6CgnWw/yN3u3m4XJTX9WK0DWzd+fexFra/7uZfbnsNohPdvKXZX+p/85aKtsCT17h///nfhVO/cXBPcGMdfPSU+/cq2gwpQ92/1fHXHn3BDmtdlddV/3CBsa7chbTpV8KMKw891DqS+f3uffb+H2Db/8Ab50ainPQlGDQp1K1r1dTgPifahrPmS9mu9qOWohPd/9WAUa1BO2lQayhLGtSzf0utdcOia0rcMOlQDb3vIQpwPeiKRe9R1+jn2a/0YI9SX9JQA+/8Ft65FzBufaU5tx57z4LfDzvegOUPwaYXXY/FmDMg93PuG8RgzF8rz3MhLn8lzPs2nP5//WuIk98Pj14Ee5e7Kk2HCx1dVXUAHjzb9dDcsMQF7b6s7Xy3485332x39YTH73e91ysfgQ2LXc9DzvHupGnqp1zxoGbWum8km8NZ6c72Ya0yv/1zRye4nkB/I3hiYNhJbvmHMfNh8IyjG+5cVw7Pftl9kz7xAlec5EhFAg4nfzX8/TLAwsJ/9XyP1LIH4YVvuHl6ky7q2dc6nLpyeP1n8OEi9x458073f93XKihWFwcC2joX0vavc5X+/IF18rzx7qR20BT3hcWgKTB4Ws+doBWsg/fuh4/+6T5HJl7oepmGntAzrxdO1j/r1j7zxrplYcbMP/zxfr8b5fLu71z59dgU94XD7C8dedhx1QFXuGnVP6BwowsxEy+AGVe7L5L6y2frgU3wwR/dlzZNdW66xuwvu3nQvfVv4PdD2c7W38GCj1yBj/I9bghis5hkyBgdCGodLkmDNK+vBynA9aC7n9vAYx/uYv0PF+CJ0pu4y8p2u964Dc+6OQtn/8idNHX1D0F1seudWPGw+1YoIcNVEjrhsz3zzV1jHTz/NTc2f8In3Ql42xPnvqy5uMSFv3MnksFSssOFOE8MfG6JG6raF3Wc73b6bcf+AV1T4k4wVzwCB9a7bz+PO9edAJTuckGtbXlrcAtRp48MXALzRQYErhOzXO/yrvdcT8T2N91JNbjwNep0F+hGz3e/V4f6/Sz4yBU8KNvthtfO/nJwPtSLtsKjl7ihMlc+7trTE2pL4b7jXZGG654LjxOS/evhhW+5ohw5M+G8X0VumPD73fDHra+0nihW7mvdnzw4ENSaw9pU10sditBakQ8f/BmWPwz15TD8FDjlFveFYF8LF75GePUu12s+9ET49F+P/u9w3gp49/fus9xEuYInJ9/cvufd1+gq0a7+hwt+/iY3VHjm1a4yaHxa8H6mSFNT4s5jPnzA/U5kjHNDztNHtA4vTM7u/hcXjbVwYGPrlyXNvdzNnxcmyo1QGjgpMGy1TUhLzAyPv4n9kAJcD/rXir18859reOXrpzNuUD85oQ+mHUvdwr7717lxy+f+/NCVrqx1JwHLH3LfGPrq3Ydr7g1uflBPT0611o1hf/m7kHkcXPlY3xzm0Vb+KvjLJ1wVrcv/Fvw/4vvWuuGUKTluseO+NlzscPPdusNaV8Rh5SPw8YsQP6B9MGsOa2nDj35YZFUh7HjTBbptb7ghz+C+aBk9NxDo5rkPdXCFV174ppvn8Om/wvDZwfkZm1Xkw6OXQsk21zsw6cLgPj/AS992w1u/+NaxD0/tCda6wP7y91zPxfHXwJl3HTxvxloXxOsr3RDl+ko3FLS++XbgUlfuTtRGngYjT+3+kNnD8fth74fub/WGZ93JaZTX/e3MnupO8Jt715rfS+GkvtK9t9/7g5vzE5vq2jp4mhvGmT3NnfBGapXiygL45/XuC4JZN8LZP+ne0PjSne7zceWj0FjtRsIcf62rZrn2SVfcImmQGwY+42oYOCFoP0qf0NQAG/4D79/vPnc7iknufO5Y81DF5uu4VLfOWfPw4+ZL0ZbWAiExSa2/e82/iwMnRc4c635EAa4HbSqoYMG9S7n3MzO4eGYvTrbvS3xNsPKvrmJlXbkLZPO/23oyX1fhPgCWP+x6HWJTXIn/3BtCU1hk2+uuQAPApx92H1ThoGSHO5kv2Q5jz3Lt6s4HckM1/Pl0983dTW/3XLjasdQNlRs83VW37MmTyt5ytPPdwlXzelrbXoPtb7j/q/rA2pfZU13PyZaX3dCnyx7sufWiakrgscvdt/2fvBdOuC54z134sZvfOfMauODe4D1vMNVVuHUU3/+j6/kfOLFDUKs8TPW2NqITXO+Hr8FVaBtxsqssOPZMdwLX3S9o/H7IW+7mO69/1g3Z9cTCuLPcvOfx50TeyAVfE2x6zhW42bfW9Yw21bp93jj37zZ4mgt0g6e7LyDD/UR45zvw9PXufXPBb4NbEbi5R+mDP7tqg1HR7ourGQvd8MBIDby9qaakkyqO+92XIG0rOTbWHPxYT0z7QiIpQ9oEtcAlbWTf603uoxTgelCjz8/kO5dw3ckj+O75YTQJNRLVlMAbP3Nld+NS3STq4q1u7Z7GavfhmPs5N+8n1BNVS7bDE1dD4SZXjOXkr/T+EANrXbncTS/CphdcuAU3d6Sp1v0bTrgAplziTrCPtlrY4lvct6nXPecqOvWkDYtdT9XAyXDuPa53IFJ1Z75buPM1uaGg219zwy0LPgqs8/idnh/u1lDthmlufdXNCzv1693/nbPWfXmwdzncujI8e4LaOrDRLTtQW+p+v2OTA5eU1tuH2h6b4k6eG2th17sulG991f0NAxfGx5wJY89wQ2aPZo3HvctdL9v6Z12PrSfGfYnUHNr6yvsf3O9A8VYoWOt+F/atcbfrAl9smCjXy9gS6qa5kOeJdvOKrA1c/EDgumV7Z9tsa8n07mpbZGjAKFdkqKeKZzTVu7m72dPC//cqElnrAnjHoFe13/XONYe1vjaqpZ9RgOthF/7+bZLjvPzj80EeOtRf7V/vlh3YudSFkamXueA25PhQt6y9+ip49iZXXn/aZ9w3mT39zauvEXa+7QLbx/91J0smylVjO+48mHCeqwy2/XVY9293XEOlG2I36UI332DkqUc+2d7wH3eyfOrX3dpUvWHTi/Df/3MTqCde6OZSDRjVO68dLMGc7yYHa2qAZ7/kqtadfLN7b3anjPnmJa5n75yfui9h+qPyvYEw9z/3d6OuHDDu7+2YM12vyZAT2vecNA/hXf9v97eifI8LbWPOdKHtuAXdK2ATaax18z8L1rpeuubrjkWDuiN1WGsgbL5OGdL1LzHqKlyhko2LA0WG/tC3grVIH6QA18O+/e+1/HddAau+fxZGEz2Dw1p3Epw+MrwnOPv9sPSX8PpPXKGBz/wj+OtW1VW4b8o/fhE2v+yGsHnj3RDJCee7b7gP9Q1nY5177Pp/w8cvuZ7MxCxXMGbypS74dQwY5XluSNmAUXDDy7279k5jrfuGeOlvXDW62V+G074ZGScaPTXfTdrz++Gl212VRk+s60EYPL31MnBy18pWNzXAH08GDHzp3chdYyqYfE2u2u7W/7ky53krXE9QbGrr/MfSna6nrXy3Gx43tjm0ndu/QltXVBW6MFe02f07mijAuGtjApe226I62WbcPNDmUFi8FQict8UPaD98c/B0t8Zpx7/p+zfAU9e4YfZn/dB9+aFzFZGwpwDXwx59fxfff3Yd79xxBkPSwnzsu/SMTS/Av290c0w+82j3CzlUFrjAtukFN/fC1+AqbY4/1/WyjZ5/9HPFGmpgyxI3P2XzEle5MHkwTLoYplzqqpBZP/ztIvft+k1L3fytUKjYB6/9yFUtS8xyCyvPXBh+pdR9jW7Iyvpn3fpdkTzfLZJY63qgd7/bOoytZQibx80RaxvqBk2B2KT2z/Hu711BoqufdnO05GA1Ja6gzdZXYetrrkcpyuu+PJp8iev1D+cv2Pqi+io3SqV5CGfBWje0tnneU3RioJpnoJfO1+iK4MQmw6cehpFa8kgkUijA9bCVu0u59A/vsuiaEzh7cnaomyOhcmAjPHGVG0Z3+rdc4Gqqd9Uym9pc2t2vcx+8TXWuR6Cpzs31Kd7injN9lOtlm3C+W6MrWAGmvgo2v+SGWW59xbUhdRhkTXD3L7rfBaZQy1sJS74Du99zpcUX/LTnSsm35Wt0Vf+qClyYrtwXuG572ecqqzXra/PdIom1boHZ5jC3b62bH1pdGDjAuNLYzYEuczz8+wvui5ar/xnKlkcOa6F4W/DmY0nwNC+A3nb4ZsFHrSXih5/iCm4l6/xEJJIowPWw2gYfk+98iVvOGMfXzxof6uZIKNWWwtOfc8OPOvLEuqpl3hh37Ynp5H6su2RPd6Ft4MSeH+pSV+7mn63/t5sLM+kiV1EwXIbYWOsKJLz8Azdsa8In3bqB3V3CwVo3/2fvh67Udcm21nBWXUjLMKVmJgoSB7oSzsmDA2WbA2Wc00fAqHma7xZOrHX/ly2hLnBpXhYhygtffl+9pdI3+f1QugMq8txQ+e7MFRWRkFCA6wVn/uoNRmUm8ZfrOv13lv6k+cQxytsayDwx4ROIDqeh2oXJcBuqCIH5cffD0l+7HsPZX3I9nV2dd9NY507g934Iez6EvctaFxP2xkPmWEjOaV1bJzm7fVBLzFIJ7L6guhgK1rj/8xEnh7o1IiIinTpcgNPZSJBMzkll+c6SUDdDwoExkDI41K04NqFenuFwouNdYJu50M2Pe/d3sPoxOON7bsHYjqGzfG9rUNvzoQtv/ka3L22Eq8Y5dBYMO9HNkdI31P1DYkb4rN0oIiJyDBTggmRyTgqL1+RTWt1AeqKqmYn0mORsN0fvxM/DS9+B57/m1g487Ruu+EnzkMjmEt7eeFch9OQvBwLbLEgaGNIfQURERORYKcAFyeQcN4xrw74K5ozVopUiPS5nJlz/oluH6pXvw9M3uO1pw2HEKS6oDT3RLWaq3jURERHpIxTggmRyjqs8tz6/XAFOpLcYA5MvhvELXM9b5nGuyIiIiIhIH6UAFyTpiTHkpMaxPr8i1E0R6X+i43pneQERERGREFPN6yCalJOqACciIiIiIj1GAS6IJueksL2witoGX6ibIiIiIiIifZACXBBNzknBb2FjgXrhREREREQk+BTggmhSSyETBTgREREREQk+BbggGpIWT2p8NBvyy0PdFBERERER6YMU4ILIGMPknBT1wImIiIiISI9QgAuyyTkpbCqopMnnD3VTRERERESkj1GAC7LJOak0NPnZVlgd6qaIiIiIiEgfowAXZJNbCploHpyIiIiIiASXAlyQjc5KIi46SvPgREREREQk6LoU4IwxC4wxHxtjthpj7uhk/3BjzOvGmFXGmLXGmPMC20caY2qNMasDlz8F+wcIN54ow4TsFPXAiYiIiIhI0HmPdIAxxgPcD5wF7AWWGWMWW2s3tDnse8BT1to/GmMmAS8CIwP7tllrZwS11WFuUk4Kz6/Jx1qLMSbUzRERERERkT6iKz1ws4Ct1trt1toG4Angog7HWCAlcDsVyA9eEyPP5JwUKuqa2FtaG+qmiIiIiIhIH9KVADcE2NPm/t7AtrbuAhYaY/biet9uabNvVGBo5ZvGmNM6ewFjzI3GmOXGmOWFhYVdb32YmpyTCqiQiYiIiIiIBFewiphcCfzVWjsUOA941BgTBewDhltrZwLfAB4zxqR0fLC1dpG1Ntdam5uVlRWkJoXOhOxkPFGGDSpkIiIiIiIiQdSVAJcHDGtzf2hgW1ufA54CsNa+B8QBmdbaemttcWD7CmAbML67jQ53cdEexmQlqhKliIiIiIgEVVcC3DJgnDFmlDEmBrgCWNzhmN3AmQDGmIm4AFdojMkKFEHBGDMaGAdsD1bjw9nknFQFOBERERERCaojBjhrbRNwM7AE2IirNrneGHO3MebCwGHfBL5gjFkDPA581lprgdOBtcaY1cDTwE3W2pIe+DnCzuScFAoq6iiuqg91U0REREREpI844jICANbaF3HFSdpu+0Gb2xuAOZ087l/Av7rZxog0KcdN9VufX8Hp4yN/Xp+IiIiIiIResIqYSAeTBzdXotQwShERERERCQ4FuB6SmhDNkLR4LSUgIiIiIiJBowDXgybnpGgpARERERERCRoFuB40OSeVHcXVVNc3hbopIiIiIiLSByjA9aDJOSlYC5sK1AsnIiIiIiLdpwDXgyYPaa1EKSIiIiIi0l0KcD0oOyWOAYkxrM9TgBMRERERke5TgOtBxhgm56Swfp8qUYqIiIiISPcpwPWwSTkpbC6ootHnD3VTREREREQkwinA9bDJOak0+Pxs2V8V6qaIiIiIiEiEU4DrYZMGNxcy0TBKERERERHpHgW4HjYqM5H4aI8qUYqIiIiISLcpwPUwT5RhUk4Kb28toqFJ8+BEREREROTYKcD1ghtPH83WA1X87rUtoW6KiIiIiIhEMAW4XnDO5GwuO34o97++lZW7S0PdHBERERERiVAKcL3kzgsnMTg1nm88uZqahqZQN0dERERERCKQAlwvSYmL5pefns6ukhp++uLGUDdHREREREQikAJcLzp5TAafmzOKv7+/mzc3F4a6OSIiIiIiEmEU4HrZt845jvGDkrjtn2soq2kIdXNERERERCSCKMD1srhoD7++fAYl1Q1879l1oW6OiIiIiIhEEAW4EJgyJJWvfWIcz6/dx39W54W6OSIiIiIiEiEU4ELkprljmDk8je8/u4595bWhbo6IiIiIiEQABbgQ8Xqi+M3lM2j0Wf7v6bVYa0PdJBERERERCXMKcCE0MjOR754/kaVbinj0/V2hbo6IiIiIiIQ5BbgQu/qk4cw7LoufvriRbYVVoW6OiIiIiIiEMQW4EDPG8P8um0ZctIdvPLWGJp8/1E0SEREREZEwpQAXBgamxPHji6ewZk8Z97++LdTNERERERGRMKUAFyY+OS2Hi2bkcN9rW1i7tyzUzRERERERkTCkABdG7r5wCllJsXz9ydXUNfpC3RwREREREQkzCnBhJDUhml9+ejrbCqv5+UubQt0cEREREREJM10KcMaYBcaYj40xW40xd3Syf7gx5nVjzCpjzFpjzHlt9n078LiPjTHnBLPxfdGp4zL57CkjefidnbyztSjUzRERERERkTByxABnjPEA9wPnApOAK40xkzoc9j3gKWvtTOAK4A+Bx04K3J8MLAD+EHg+OYzbF0xgdFYi3/rnGsprG0PdHBERERERCRNd6YGbBWy11m631jYATwAXdTjGAimB26lAfuD2RcAT1tp6a+0OYGvg+eQw4mM8/ObyGRyorOeuxetD3RwREREREQkTXQlwQ4A9be7vDWxr6y5goTFmL/AicMtRPFY6MX1YGjfPH8szq/J48aN9oW6OiIiIiIiEgWAVMbkS+Ku1dihwHvCoMabLz22MudEYs9wYs7ywsDBITYp8N58xlmlDU/nuMx+RX1Yb6uaIiIiIiEiIdSVk5QHD2twfGtjW1ueApwCste8BcUBmFx+LtXaRtTbXWpublZXV9db3cdGeKH59+QwafZarHnifgvK6UDdJRERERERCqCsBbhkwzhgzyhgTgytKsrjDMbuBMwGMMRNxAa4wcNwVxphYY8woYBzwYbAa3x+MHZjEIzfMorCynisV4kRERERE+rUjBjhrbRNwM7AE2IirNrneGHO3MebCwGHfBL5gjFkDPA581jrrcT1zG4CXgK9Ya7VC9VE6YUQ6f/vcLA5U1HHVA++zv0IhTkRERESkPzLW2lC3oZ3c3Fy7fPnyUDcjLC3fWcK1D31IdkocT9w4m4EpcaFukoiIiIiIBJkxZoW1NrezfcEqYiK9IHfkAB65YRYFFXVc8cD7HKhUT5yIiIiISH+iABdhThw5gL9eP4uC8jquXPQ+hZX1oW6SiIiIiIj0EgW4CDRr1AAe/uyJ5JfVceUDCnEiIiIiIv2FAlyEOml0Bg9ffyJ5pbVc9cD7FFUpxImIiIiI9HUKcBFs9ugMHvrsiewpreGqB96nWCFORERERKRPU4CLcCePyeCh605kd0kNVz3wgUKciIiIiEgfpgDXB5wyNpMHrzuRncXVXP2XDyipbgh1k0REREREpAcowPURcwIhbkdRNVc98L5CnIiIiIhIH6QA14ecOi6Tv1yXy44i1xNXqhAnIiIiItKnKMD1MaeNy+KBa3PZVljF1X/5gLIahTgRERERkb5CAa4POn28C3FbFeJERERERPoUBbg+au74LBZdcwJb9lfx6T+9x8Z9FaFukoiIiIiIdJMCXB8277iBPHz9iZTWNHLR79/hL0u34/fbUDdLRERERESOkQJcHzdnbCZLvnYac4/L4scvbGThgx+QX1Yb6maJiIiIiMgxUIDrBzKSYll0zQn8/LKprN5TxoJ732LxmvxQN0tERERERI6SAlw/YYzhMycO579fPY0xA5O49fFVfPWJVZTXNoa6aSIiIiIi0kUKcP3MiIxE/vnFk/nGWeN5fu0+zr33Ld7bVhzqZomIiIiISBcowPVDXk8Ut545jn996RRioz1c9Zf3+emLG6lv8oW6aSIiIiIichgKcP3YjGFpvHDrqVw5aziL3trORb9/h48LKkPdLBEREREROQQFuH4uIcbLTy+ZyoPX5VJUVc8Fv3+bB9/eoeUGRERERETCkAKcAHDmxEG89LXTOX1cJj96fgPXPPQB+8q13ICIiIiISDhRgJMWmUmxPHBtLj+7dCord5Vxzm/e4vm1Wm5ARERERCRcKMBJO8YYrpw1nBe/ehqjs5K4+bFVXPPgB6zdWxbqpomIiIiI9HsKcNKpUZmJPH3TyXzv/Imsyyvnwt+/w02PrmDLfhU5EREREREJFWNteBWryM3NtcuXLw91M6SNyrpGHnp7Jw8s3U51QxOXzBzC1z8xnmEDEkLdNBERERGRPscYs8Jam9vpPgU46arS6gb+9OY2/vruTvzWcsWJw7nljLEMTIkLddNERERERPoMBTgJqv0VdfzutS088eEevB7DdaeM5KbTx5CeGBPqpomIiIiIRDwFOOkRu4truPfVzTyzOo+kGC9fOH00N5w6iqRYb6ibJiIiIiISsRTgpEd9XFDJr1/5mCXr9zMgMYYvzxvDwtkjiIv2hLppIiIiIiIRRwFOesXqPWX86uWPWbqliMGpcdx65jg+dcJQoj0qdioiIiIi0lUKcNKr3t1WxC+WfMyq3WUMTY/nmtkjuDx3mObIiYiIiIh0QbcDnDFmAfBbwAP8xVp7T4f9vwHmB+4mAAOttWmBfT7go8C+3dbaCw/3WgpwfYO1lv9tPMADS7fzwY4SYrxRXDAth2tPHsH0YWmhbp6IiIiISNjqVoAzxniAzcBZwF5gGXCltXbDIY6/BZhprb0hcL/KWpvU1cYqwPU9HxdU8uj7O3lmZR7VDT6mD01l4ewRXDA9R/PkREREREQ66G6AOxm4y1p7TuD+twGstT87xPHvAndaa18J3FeAE8AtCP7Mqjz+9t4uth6oIi0hms/kDmPh7BFaFFxEREREJKC7Ae5TwAJr7ecD968BTrLW3tzJsSOA94Gh1lpfYFsTsBpoAu6x1j7byeNuBG4EGD58+Am7du3q8g8nkcday3vbi3n0vV28vGE/fmuZNz6La08eydzxWURFmVA3UUREREQkZA4X4IK9YNcVwNPN4S1ghLU2zxgzGnjNGPORtXZb2wdZaxcBi8D1wAW5TRJmjDGcMiaTU8ZkUlBex2Mf7ubxD3dz/V+XMXxAAgtnD+fTJ6joiYiIiIhIR12p754HDGtzf2hgW2euAB5vu8Famxe43g68Acw86lZKn5WdGsc3zhrPO7efwe+unEl2ahw/fXETs3/2P771zzWs2l1KuFVKFREREREJla70wC0DxhljRuGC2xXAVR0PMsZMANKB99psSwdqrLX1xphMYA7w/4LRcOlbYrxRXDA9hwum57CpoIJH39vFM6vyeHrFXiYNTuHKk4Zz8YwckuOiQ91UEREREZGQ6eoyAucB9+KWEXjIWvsTY8zdwHJr7eLAMXcBcdbaO9o87hTgz4Af19t3r7X2wcO9loqYSLPKukb+szqfxz7YzYZ9FSTEeLhweg5XnTScaUPTQt08EREREZEeoYW8JaJZa1mzt5zHPtjFc2v2UdvoY8qQFK6aNYILZ+SQFBvsqZwiIiIiIqGjACd9RkVdI8+uyuOxD3azqaCSxBgPF80cwlWzhjNlSGqomyciIiIi0m0KcNLnWGtZubuMxz/czfNr86lr9DNtaCpXzRrOBdNzSFSvnIiIiIhEKAU46dPKaxp5ZtVeHvtwN5v3V5EU6+XimTlcceJwJuekYIzWlRMRERGRyKEAJ/2CtZYVu0p57IPdPP/RPhqa/IwflMTFM4dw0YwhDEmLD3UTRURERESOSAFO+p2ymgaeW7uP/6zKY/muUgBmjRrAxTOGcP7UwaQmaDkCEREREQlPCnDSr+0pqeE/q/N4ZlUe2wqrifFEMe+4LC6eOYQzJgwkLtoT6iaKiIiIiLRQgBPBDbFcl1fBs6vzWLwmn8LKepLjvJw7JZuLZw5h9qgMoqI0X05EREREQksBTqQDn9/y7rYinl2Vz0vr9lHd4CM7JY6LZuRw0YwhTBycrOInIiIiIhISCnAih1Hb4OPVjft5dlUeb24upMlvOW5QMqePz2Tm8HRmDk9jcKoKoIiIiIhI71CAE+mikuoGXlibz3Nr9rF6TxkNPj8A2SlxzByexszhacwYls7UIanEx2junIiIiIgEnwKcyDGob/KxcV8lq3eXsmpPGat2l7G7pAYAT5Rh4uBkZg5LDwS7dEZmJGjYpYiIiIh0mwKcSJAUVdWzencZq/aUsnpPGWv2lFNV3wRAWkI0M4e5MHf88HRyR6arwqWIiIiIHLXDBThvbzdGJJJlJsXyiUmD+MSkQYArhrL1QBWrdpeyKhDs3thciLUQ440id0Q6c8ZmMmdsJlOHpOJRlUsRERER6Qb1wIkEWWVdI8t3lfLu1iLe3lrMxn0VAKTEeZk9OoNTx7lANzozUUMuRUREROQg6oET6UXJcdHMP24g848bCLhhl+9tK+adrUUs3VLEyxv2A64wypyxmZw6LoM5YzIZmBIXymaLiIiISARQD5xIL7LWsrukhne2ukD3zrYiymoaARg3MKlluOVJoweQEhcd4taKiIiISCioiIlImPL7LRv2VfDO1iLe3lrEsp0l1DX68UQZpg5JZc7YDE4Zk8kJI1QQRURERKS/UIATiRD1TT5W7CptGXK5Zm85Pr8lxhvFCcPTXaAbm8m0Ial4PVGhbq6IiIiI9AAFOJEIVVXfxIc7inlnazHvbmstiJIU6+WkUQM4eUwGc8ZmctygZKJU4VJERESkT1ARE5EIlRTr5YwJgzhjglu2oLiqnve3l/DOtiLe3VrE/zYdACAjMYbZY1wxlFPGZDBCi4qLiIiI9EnqgROJYHlltby7tcgNudxWxP6KegCGpMVz6thMTgnMoctKjg1xS0VERESkqzSEUqQfsNayvajaVbcMhLqKuiYAJmQnuyULxmYya9QAEmPV+S4iIiISrhTgRPohn9+yLq+ct7cW8e62IpbtLKWhyY83yjBzeFrLkgUzhqURrYIoIiIiImFDAU5EqGt0FS7f3urmz63NK8daSIzxcNLoDE4Zk8Gp4zIZP1AFUURERERCSUVMRIS4aE9LrxtAWU0D728vbllU/LVAQZT4aA9jByYxbmASYwclMW5gMuMHJTE0PQGPgp2IiIhISKkHTkQAyC+r5d1txWzIr2DLgUq2HqhiX3ldy/5YbxRjspIYN8iFu3GDkhk3MInhAxK0Jp2IiIhIEKkHTkSOKCctnk+dMBROaN1WUdfItgNVbNlfxZYDlWw5UMXynaX8Z3V+yzExnihGZyUydmAS4wclMzknhSlDUhmYHKulDERERESCTAFORA4pJS6amcPTmTk8vd326vomth6oYssBF+y27q9i7d5yXvhoH82d+plJsUwZksKUnFSmDElhck4qQ9PjFepEREREukEBTkSOWmKsl+nD0pg+LK3d9qr6Jjbuq2BdXjnr8ipYn1/O0i1F+Pwu1aXGR7f00DVfj8pIVNEUERERkS5SgBORoEmK9XLiyAGcOHJAy7a6Rh8fF1SyLr811P31nZ00+PyAq4I5Kcf10E3KSWHS4BTGDUoi1usJ1Y8hIiIiEra6FOCMMQuA3wIe4C/W2ns67P8NMD9wNwEYaK1NC+y7DvheYN+PrbWPBKHdIhIh4qI9B/XWNfr8bNlfxbr8ctbnlbMuv4Inl+2httEHgCfKMDYriYmDk5k4OKXlkpUcG6KfQkRERCQ8HLEKpTHGA2wGzgL2AsuAK621Gw5x/C3ATGvtDcaYAcByIBewwArgBGtt6aFeT1UoRfonn9+ys7iajfsqApdKNuRXUFDRWgkzKzk2EOaSmRQIdaMzE1UFU0RERPqU7lahnAVstdZuDzzZE8BFQKcBDrgSuDNw+xzgFWttSeCxrwALgMe73nwR6Q88UYYxWUmMyUrik9NyWraXVjewcV8FGwKhbuO+Ch7aVkSjz335FOON4rhByUzITmZUViIjMxIZPiCBkZmJJMVqlLiIiIj0LV05uxkC7Glzfy9wUmcHGmNGAKOA1w7z2CFH30wR6a/SE2M4ZWwmpwQWIAc3BHNbYRUb8lt7697YXMg/V+xt99jMpBhGZCQyIiOBkR2u0xJievtHEREREem2YH89fQXwtLXWdzQPMsbcCNwIMHz48CA3SUT6mmhPFBOyU5iQndJue1V9E7uLa9hVXM3Olutq3ttWzL9X5rU7NjU+mpEZCYzISGRkRgKjs9w6dmMGJqqAioiIiIStrgS4PGBYm/tDA9s6cwXwlQ6PndfhsW90fJC1dhGwCNwcuC60SUTkIEmxXlfJMifloH11jT72lNS0C3a7imtYtaeU59fmE1jpAE+UYWRGAsdlJzN+UDLHDUpmfHYyIwYkaK6diIiIhFxXAtwyYJwxZhQukF0BXNXxIGPMBCAdeK/N5iXAT40xzasAnw18u1stFhE5BnHRHsYNSmbcoOSD9jU0+dlZXM3HBZVs3l/JxwWugMp/1xW0LEwe441ibFZSa7DLdj12Q9K0OLmIiIj0niMGOGttkzHmZlwY8wAPWWvXG2PuBpZbaxcHDr0CeMK2KWtprS0xxvwIFwIB7m4uaCIiEi5ivFGMH+SCWVu1DT62Hqji4/2twe797cU8s6p1EEJSrJexA5MYmZHA8EABlREZCQwfkMDA5FiFOxEREQmqIy4j0Nu0jICIhLvy2ka27K90wa6gks37q9hdUkN+eS1t/6TGRUcxLN0FumEDEhgxIIHhGQkMH5DI0PR44qI1105EREQO1t1lBEREpI3U+GhyRw4gd+SAdtvrm3zkldayu6TGXYpr2FVSw56SGt7ZWtyyUDmAMZCdEtca7ALhbljgdkZijHrvRERE5CAKcCIiQRLr9TA6K4nRWUkH7bPWUlTVwO6S6kC4q2VXSTW7i2t4c3MhByrr2x2fEONh+IDWQDe8pfcugSFp6r0TERHprxTgRER6gTGGrORYspJjOWHEgIP21zb42Fta09p7F+i521VczdIthdQ1+ts8V2vv3bD0BIamxzMkLZ4hgevBaXFaCkFERKSPUoATEQkD8TGHrpJpraWwqp49LUMza1sC3jtbi9hfWUfH6cxZybEu1LUJdjnN99PiSYn3aoimiIhIBFKAExEJc8YYBibHMTA5rtPeu4YmPwXldeSV1bpLaS35gdsb9lXwysb9NDT52z0mKdbLkLR4hqbHMzzDzcMbkZnIiAEJDE1PIMarNe9ERETCkQKciEiEi/FGuflxGQmd7m+ef5dXFgh2pS7c7S2tZW9pDe9ua19gJcrA4NR4Rma6ipkjmgNehrudGKuPDhERkVDRp7CISB/Xdv7djGFpB+1vHqK5u7iGXcVu3t2uEnd7yfoCSqob2h2fmRQTWO8ukYEpsWQlxZLZfEmOITMplvSEGDxRGqIpIiISbApwIiL9XNshmh2XRgCoqGtsCXc7i6sDyyNU8+GOEg5U1tHoO3g90SgDAxJjyUyKISu5OeDFtAl6Lvhlp8aRnhCt+XgiIiJdpAAnIiKHlRIXzZQhqUwZknrQPmstFbVNFFbVU9R8qaynqKqh5X5hVQPbC6spqqqnvsNcPHBDQLNT4shOiWNQahzZKbEMSokjOzWOwalxDEpx4VLz8kRERBTgRESkG4wxpCZEk5oQzdiBB69/15a1lqr6ppZwd6CinoKKOvZX1FFQXkdBRR1r95bxcnldp0EvMynGBbtAuBuSHs/QdLcu3rD0eDKTYonSsE0REenjFOBERKRXGGNIjosmOS6aUZmJhzzOWktZTSMFFS7U7Q+Eu+agl19ex8rdpZTWNLZ7XIw3iqGBZROGBtbHGxq4rYAnIiJ9hQKciIiEFWMM6YkxpCfGMHFwyiGPq2loIq+0tZrm3ja3X84voLhD8ZUYb1TL0gnZKXGkxkeTlhBNanw0KfHuuuPF69GwTRERCS8KcCIiEpESYryHXPwcXMDLL6tlTychb8v+IsprG9stn9CZpFhvm4DnbqfFxzAgKYaMRFeUJSMphoxAwZb0xBiiFfpERKQHKcCJiEiflBDjZezAZMYO7DzggVsEvby2sc2lwV3XNFJe20R5bSNltQ1UBPbvKKqmrKaM0pqGTqtvAqQlRLtg1yHgZSTFtFTlzE6NZ2ByrMKeiIgcNQU4ERHpt2K8US1r5B0Nay0VdU0UVdVTXNVAcVU9RdWB65ZtDWwsqKC4yoXCjqIMLWEuJ9UVZslJjXfXaXFkp8YzKDlWwzhFRKQdBTgREZGjZIxpmSc3JuvIxzc0+SmpdtU3Cyvr2VdeR0F5LfnlrjDL5v2VvLm5kJqG9kM6m0Pe4NR4BqfGMTg1ngGJbkhnSlw0KfHewHXr/fhoj9bVExHpwxTgREREeliMN4rsQC/boTT36u0rr2VfeR37yroW8jryRplAoPMeFPRSE6LJSoplYEocA5Nj3SUljqRYnQ6IiEQK/cUWEREJA2179SZkH7r6Zn2Tj8q6JipqG6louW6korYpcH3w/YKKOipqGymraaTBd/AaewkxnkCgiyMrxQW7QS0hL46BgW2p8dHq3RMRCTEFOBERkQgS6/UQm+QhM+no5u2B6+Urr23kQKVbSP1AZd1BtzfkV/BGRR3VnfT0xXijGJQSS3ZKHAMDi6oPSnFhr/USS0KMTi9ERHqK/sKKiIj0E8YY0hJiSEuIYfwhll9oVl3fFAh3dewPXBdW1rcsqr4hv4LXNh7odCmG5DgvgwIBb2Ag4GUlxZIQ4yE+xkOs113HR3uIi44KXLtLfIyHOG+UireIiByCApyIiIgcJDHWy6hYL6MyEw95jLWWyvomF/Iq6ikor2N/ZR37ywP3K+rYvq2KA5X1NPk7X3bhUKI9pjXURXtIC8zfa64ampUcG5jPF0tWUhxZybHEx3i6+2OLiIQ9BTgRERE5JsYYVyQlLvqw6+35/bZl4fTaRh+1DT7qm3zUNvipbfRRF9he37LfT12TO655X1lNI/nldazZW05xdT22kzyYFOttCXZtg15mUgxJsdEkxXlJivWSHOclMdbdTor14onSvD4RiRwKcCIiItKjoqIM6YkxpAfp+Zp8fkpqGiisrG+9VNW3u7+xoIK3ttRTWdd0xOdLiPGQGOslOdbbEvLa3m8Oe8lxraEvqc2xSXFekmOjiYuOUpEXEelxCnAiIiISUbyeKFcdM/nQyzI0q2v0UVzdQFVdE1X1jVTWNVFd72u5XVXfRHW9u3b73O09JTVUN7htVXVNXRoCGmUIBL3oQAj0kBQXTVKsh4QYF/aaw2Ji83XzpWW7e1xirJdYrwKhiBxMAU5ERET6rLhoD0PS4rv1HNZa6pv8LWGvOfhVBa4rm0NgXWsQrKpvpKq+ifKaBvLLfFQHjqlu8OHr4nxAT5QhIVDYpbnoS0LLbS/xMZ52+9vdDhzTHAabexWTAmFRRWJEIpcCnIiIiMhhGNNaUOVYlm9oqzkMVtc3UdPgo7ohEOzqfS0Bz103tRxT2+Bz14H5g7WNPkqqa6lr9FHT0NSyrdHX9UIxcdFRLaEuMcbb0mPYNuwlxniIjfYQ641yl5bbHmKjo4gLXDdvi4tu3RfrjSLGox5EkZ6gACciIiLSS9qGwYwgP3ejz98a8gLhsKbB19Jz6IaH+lqGibbf3kRRVQO7imtattc0+jotFtNV3ijTMmS03XWMl4RAQEwIDBlte50Q4yElLpqs5NYF5KNUaEakhQKciIiISB8Q7Yki2hNFSlx0UJ7PWkujz1Lf5KOu0U99k4/6Jj/1ja5KaH1gW/t97tr1DrpL297GmgYf+yvrqCkK3K9314cbVRrtMWQmxXZaYbTjfS0iL/2B3uUiIiIichBjDDFeQ4w3ii7UizlmnQ0rLatppKhDZdHCKre24Ed55RRV1Xca+hJjPGQmxxIf7SHG6wJtjCeKaG8UMR7TybaowDbjtgeGg8ZHe4iPiWqZa9g8/7B5sfnm+YYqNCOhoAAnIiIiIiFzLMNKfX5L6SGWkiiqqqeu0UdDk59Gn6WhyU9tbWPgvp8Gn5/GJj8NPktDk5s72ODzd7m4TPu248JedGuhmeaQ2BwKD77d4b7XEB0V1RIgE2Pd8yTGuvCYGBhWmhAYcpoQ6wKkCtH0XwpwIiIiIhJRPFFuWGVmUiwTBwfnOX1+S6PPDRFtu+h8bWMTtQ1+VzAmsPB8c1GZurYFZgLHu5BoXUhs8lPd4KMxEB6b/LYlSDb6/DQFwmODz3/U8w1jvFEtcwpd0PO0BOG46Ch37W1zu+O+QCGajttjvVHtt3k9moMYZroU4IwxC4DfAh7gL9baezo55nLgLsACa6y1VwW2+4CPAoftttZeGIR2i4iIiIgEjSfK4IlywSWV4MwjPBo+v5tvWNOhCE1Nvas22jynsPl2daACaXWb/bWNPspqGqgLzFOsbXCBsy4QJo9VtMcEqo62D4DN1UfjvB7iAkNL3VIX3nbLXjT3IHa6PTBMNcarHsWuOmKAM8Z4gPuBs4C9wDJjzGJr7YY2x4wDvg3MsdaWGmMGtnmKWmvtjOA2W0RERESk7/BEmUAVzp4ZIOf325YCM63hzgW9ukZXlKZ5X+vtwHXgfnOhmrqm1m21DT5Kqxvd7cbWANrgO7rAGO1xP39ijOewVUo72x/bprcx1tt5b6KnD/UiduUdMgvYaq3dDmCMeQK4CNjQ5pgvAPdba0sBrLUHgt1QERERERE5NlFRpmWh997Q1GZZi5oOaxk2D0et7dCreFDV0nof+8rrDtp+LMtbeKNMu57DtmsZ3nfFTIYNSAj+P0IP6UqAGwLsaXN/L3BSh2PGAxhj3sENs7zLWvtSYF+cMWY50ATcY619tuMLGGNuBG4EGD58+NG0X0REREREwozXE0WyJ4rkIC1r0cxaS12jvyXgVdW7MFjfYWmLujZLWtS13d7cw9jka1n2IjrCCsIEq4/WC4wD5gFDgbeMMVOttWXACGttnjFmNPCaMeYja+22tg+21i4CFgHk5uZ2Y8lIERERERHpq4xp05OYFOrWhEZX4mYeMKzN/aGBbW3tBRZbaxuttTuAzbhAh7U2L3C9HXgDmNnNNouIiIiIiPRLXQlwy4BxxphRxpgY4ApgcYdjnsX1vmGMycQNqdxujEk3xsS22T6H9nPnREREREREpIuOOITSWttkjLkZWIKb3/aQtXa9MeZuYLm1dnFg39nGmA2AD7jNWltsjDkF+LMxxo8Li/e0rV4pIiIiIiIiXWfssZRx6UG5ubl2+fLloW6GiIiIiIhISBhjVlhrczvbF1klV0RERERERPoxBTgREREREZEIoQAnIiIiIiISIRTgREREREREIoQCnIiIiIiISIRQgBMREREREYkQCnAiIiIiIiIRQgFOREREREQkQijAiYiIiIiIRAhjrQ11G9oxxhQCu0Ldjk5kAkWhboT0G3q/SW/Re016i95r0pv0fpPe0lPvtRHW2qzOdoRdgAtXxpjl1trcULdD+ge936S36L0mvUXvNelNer9JbwnFe01DKEVERERERCKEApyIiIiIiEiEUIDrukWhboD0K3q/SW/Re016i95r0pv0fpPe0uvvNc2BExERERERiRDqgRMREREREYkQCnBdYIxZYIz52Biz1RhzR6jbI32LMeYhY8wBY8y6NtsGGGNeMcZsCVynh7KN0jcYY4YZY143xmwwxqw3xnw1sF3vNwkqY0ycMeZDY8yawHvth4Hto4wxHwQ+T580xsSEuq3SNxhjPMaYVcaY5wP39V6ToDPG7DTGfGSMWW2MWR7Y1uufoQpwR2CM8QD3A+cCk4ArjTGTQtsq6WP+CizosO0O4H/W2nHA/wL3RbqrCfimtXYSMBv4SuDvmd5vEmz1wBnW2unADGCBMWY28HPgN9basUAp8LnQNVH6mK8CG9vc13tNesp8a+2MNksH9PpnqALckc0Ctlprt1trG4AngItC3CbpQ6y1bwElHTZfBDwSuP0IcHFvtkn6JmvtPmvtysDtStzJzhD0fpMgs05V4G504GKBM4CnA9v1XpOgMMYMBc4H/hK4b9B7TXpPr3+GKsAd2RBgT5v7ewPbRHrSIGvtvsDtAmBQKBsjfY8xZiQwE/gAvd+kBwSGtK0GDgCvANuAMmttU+AQfZ5KsNwL/B/gD9zPQO816RkWeNkYs8IYc2NgW69/hnp7+gVEpHustdYYo3KxEjTGmCTgX8DXrLUV7stqR+83CRZrrQ+YYYxJA54BJoS2RdIXGWM+CRyw1q4wxswLcXOk7zvVWptnjBkIvGKM2dR2Z299hqoH7sjygGFt7g8NbBPpSfuNMYMBAtcHQtwe6SOMMdG48PYPa+2/A5v1fpMeY60tA14HTgbSjDHNXx7r81SCYQ5woTFmJ26ayxnAb9F7TXqAtTYvcH0A98XULELwGaoAd2TLgHGBakYxwBXA4hC3Sfq+xcB1gdvXAf8JYVukjwjMC3kQ2Git/XWbXXq/SVAZY7ICPW8YY+KBs3BzLl8HPhU4TO816TZr7bettUOttSNx52ivWWuvRu81CTJjTKIxJrn5NnA2sI4QfIZqIe8uMMachxtf7QEestb+JLQtkr7EGPM4MA/IBPYDdwLPAk8Bw4FdwOXW2o6FTkSOijHmVGAp8BGtc0W+g5sHp/ebBI0xZhpuMr8H92XxU9bau40xo3G9JAOAVcBCa2196FoqfUlgCOW3rLWf1HtNgi3wnnomcNcLPGat/YkxJoNe/gxVgBMREREREYkQGkIpIiIiIiISIRTgREREREREIoQCnIiIiIiISIRQgBMREREREYkQCnAiIiIiIiIRQgFOREREREQkQijAiYiIiIiIRAgFOBERERERkQjx/wFxI/a9UDkoBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543150a",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82f41fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.7569\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('best_val_model_pytorch')\n",
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53d1f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('best_val_model_pytorch')\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7cd62bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.7569324959853178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7419    0.7405    0.7412     47915\n",
      "           1     0.8108    0.7764    0.7932     48050\n",
      "           2     0.7184    0.7536    0.7356     43523\n",
      "\n",
      "    accuracy                         0.7569    139488\n",
      "   macro avg     0.7570    0.7568    0.7567    139488\n",
      "weighted avg     0.7583    0.7569    0.7574    139488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01c4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad26842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138f389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd039b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
